{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3397ff17-b0ed-4e5b-9028-d9f877da8595",
   "metadata": {
    "language": "sql",
    "name": "cell4",
    "resultHeight": 111
   },
   "outputs": [],
   "source": "CREATE OR REPLACE STAGE my_stage\n    DIRECTORY = ( ENABLE = true )\n    ENCRYPTION = ( TYPE = 'SNOWFLAKE_SSE' );\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e07475aa-f670-469c-8f42-68de7e9bad6b",
   "metadata": {
    "language": "sql",
    "name": "cell1",
    "collapsed": false,
    "resultHeight": 111
   },
   "outputs": [],
   "source": "--we already have the files uploaded , stage created, just trying out by tutorital\n\nCREATE OR REPLACE FUNCTION SNOW_PDF.PUBLIC.pdf_chunker(file_url STRING)\n    RETURNS TABLE (chunk VARCHAR)\n    LANGUAGE PYTHON\n    RUNTIME_VERSION = '3.9'\n    HANDLER = 'pdf_text_chunker'\n    PACKAGES = ('snowflake-snowpark-python', 'PyPDF2', 'langchain')\n    AS\n$$\nfrom snowflake.snowpark.types import StringType, StructField, StructType\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom snowflake.snowpark.files import SnowflakeFile\nimport PyPDF2, io\nimport logging\nimport pandas as pd\n\nclass pdf_text_chunker:\n\n    def read_pdf(self, file_url: str) -> str:\n        logger = logging.getLogger(\"udf_logger\")\n        logger.info(f\"Opening file {file_url}\")\n\n        with SnowflakeFile.open(file_url, 'rb') as f:\n            buffer = io.BytesIO(f.readall())\n\n        reader = PyPDF2.PdfReader(buffer)\n        text = \"\"\n        for page in reader.pages:\n            try:\n                text += page.extract_text().replace('\\n', ' ').replace('\\0', ' ')\n            except:\n                text = \"Unable to Extract\"\n                logger.warn(f\"Unable to extract from file {file_url}, page {page}\")\n\n        return text\n\n    def process(self, file_url: str):\n        text = self.read_pdf(file_url)\n\n        text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size = 2000,  # Adjust this as needed\n            chunk_overlap = 300,  # Overlap to keep chunks contextual\n            length_function = len\n        )\n\n        chunks = text_splitter.split_text(text)\n        df = pd.DataFrame(chunks, columns=['chunk'])\n\n        yield from df.itertuples(index=False, name=None)\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cefd1f32-5faf-4446-b6a9-43157fffc9a5",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "collapsed": false,
    "resultHeight": 111
   },
   "outputs": [],
   "source": "--create table to hold chunks\nCREATE OR REPLACE TABLE snow_pdf.public.docs_chunks_table AS\n    SELECT\n        relative_path,\n        build_scoped_file_url(@snow_pdf.public.my_stage, relative_path) AS file_url,\n        -- preserve file title information by concatenating relative_path with the chunk\n        CONCAT(relative_path, ': ', func.chunk) AS chunk,\n        'English' AS language\n    FROM\n        directory(@snow_pdf.public.my_stage),\n        TABLE(snow_pdf.public.pdf_chunker(build_scoped_file_url(@snow_pdf.public.my_stage, relative_path))) AS func;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fa141548-83cc-419e-bce9-4a9c9a76cb6f",
   "metadata": {
    "language": "sql",
    "name": "cell3",
    "collapsed": false,
    "resultHeight": 111
   },
   "outputs": [],
   "source": "CREATE OR REPLACE CORTEX SEARCH SERVICE bill_cortex_search\n    ON chunk\n    ATTRIBUTES language\n    WAREHOUSE = compute_wh\n    TARGET_LAG = '1 hour'\n    AS (\n    SELECT\n        chunk,\n        relative_path,\n        file_url,\n        language\n    FROM snow_pdf.public.docs_chunks_table\n    );",
   "execution_count": null
  }
 ]
}